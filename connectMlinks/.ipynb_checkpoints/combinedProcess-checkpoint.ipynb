{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = pd.read_csv('./data/gdf_s010_p010_v010.csv')\n",
    "pbdata = pd.read_csv('./data/perth_base_2011.0.countscompare.tsv',sep='\\t')\n",
    "tree = ET.parse('./data/network.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "def parseAtts(atts):\n",
    "    rd = {}\n",
    "    for att in atts:\n",
    "        name = att.attrib['name']\n",
    "        rd[name] = att.text\n",
    "    return rd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseLink(root):\n",
    "    rd  = {'id':[], 'from':[], 'to':[], 'length':[],'freespeed':[],'capacity':[],'permlanes':[],'oneway':[],'modes':[],'origid':[],'type':[]}\n",
    "    links = root[1]\n",
    "    for link in links:\n",
    "        attrdict = parseAtts(link[0])\n",
    "        linkd = {**attrdict, **link.attrib}\n",
    "        for key in linkd:\n",
    "            rd[key].append(linkd[key])\n",
    "    return rd\n",
    "\n",
    "linkd = parseLink(root)\n",
    "linkdf =  pd.DataFrame(linkd)\n",
    "linkdf.to_csv('./data/linkdf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNodesFromTree(root):\n",
    "    rd = {'id':[],'x':[],'y':[]}\n",
    "    nodes = root[0]\n",
    "    for node in nodes:\n",
    "        rd['id'].append(node.attrib['id'])\n",
    "        rd['x'].append(node.attrib['x'])\n",
    "        rd['y'].append(node.attrib['y'])\n",
    "    return rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = getNodesFromTree(root)\n",
    "nodedf = pd.DataFrame(rd)\n",
    "nodedf.to_csv('./data/nodedf.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodedf = nodedf.set_index('id')\n",
    "def getxyById(nodeid):\n",
    "    return [nodedf.at[nodeid,'x'], nodedf.at[nodeid,'y']]\n",
    "for idx,row in linkdf.iterrows():\n",
    "    fromid = row['from']\n",
    "    toid = row['to']\n",
    "    fromxy = getxyById(fromid)\n",
    "    toxy = getxyById(toid)\n",
    "    linkdf.at[idx,'x0'] = fromxy[0]\n",
    "    linkdf.at[idx,'y0'] = fromxy[1]\n",
    "    linkdf.at[idx,'x1'] = toxy[0]\n",
    "    linkdf.at[idx,'y1'] = toxy[1]\n",
    "linkdf.to_csv('./data/linknode.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlink = pd.read_csv('./data/gdf_s010_p010_v010.csv')\n",
    "link = pd.read_csv('./data/linknode.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115.821391, -31.9752)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parsePointX(pstr):\n",
    "    xy = pstr.strip('(').strip(')').split(',')\n",
    "    return float(xy[0])\n",
    "\n",
    "def parsePointY(pstr):\n",
    "    xy = pstr.strip('(').strip(')').split(',')\n",
    "    return float(xy[1])\n",
    "parsePointX('(115.821391, -31.9752)'), parsePointY('(115.821391, -31.9752)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePolyline(polylinestr):\n",
    "    return loads(polylinestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlink['polyline'] = mlink['polyline'].map(parsePolyline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = link[(link['type'] == 'motorway') | (link['type'] == 'trunk')].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344c80eb0f314b0d9c82cb119298f380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, row in tqdm_notebook(link.iterrows()):\n",
    "    miniMlink = -1\n",
    "    miniDistance = 999999\n",
    "    for midx in mlink.index:\n",
    "        pl = mlink.at[midx, 'polyline']\n",
    "        mid = mlink.at[midx, 'mlink']\n",
    "        dsum = Point(row['x0'], row['y0']).distance(pl) + Point(row['x1'], row['y1']).distance(pl)\n",
    "        if dsum < miniDistance:\n",
    "            miniMlink = mid\n",
    "            miniDistance = dsum\n",
    "    link.at[idx, 'pairedMlink'] = miniMlink\n",
    "    link.at[idx,'distanceSum'] = miniDistance\n",
    "    \n",
    "link['pairedMlink'] = link.pairedMlink.astype(int)\n",
    "link.to_csv('./data/mlinks_links_connected_total.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "countdf = pd.read_csv('./data/perth_base_2011.0.countscompare.tsv',sep='\\t')\n",
    "mldf = pd.read_csv('./data/mlinks_links_connected_total.csv')\n",
    "mlinks = pd.read_csv('./data/gdf_s010_p010_v010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mldf = mldf[mldf['distanceSum'] < 0.001]\n",
    "mldf.drop('index',axis = 1, inplace=True)\n",
    "mlinks.drop(['IRIS_PolyLine','Start_Point','End_Point','NPI_Link_ID','SCATS_Link_Name','Notes'],axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf = countdf.drop(['Count Station Id','Count volumes','Relative Error','Normalized Relative Error','GEH'],axis = 1)\n",
    "resdf= resdf.reset_index()\n",
    "for idx,row in mldf.iterrows():\n",
    "    linkid = row['id']\n",
    "    mlinkid = row['pairedMlink']\n",
    "    resdf.loc[resdf['Link Id']==linkid,'mlink'] = mlinkid\n",
    "res = resdf.dropna().reset_index()\n",
    "res.drop(['level_0','index'],axis = 1, inplace=True)\n",
    "res['mlink'] = res['mlink'].astype(int)\n",
    "res.to_csv('./data/link-mlink-count-primary.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'merge'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-e987f07d7663>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresfull\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmlinks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mlink'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mresfull\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/full-link-mlink-count-primary.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'merge'"
     ]
    }
   ],
   "source": [
    "resfull = res.merge(mlinks, on='mlink')\n",
    "resfull.to_csv('./data/full-link-mlink-count-primary.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c110e5c30ad34af4b92de7a65d1e969c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=126576), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/full-link-mlink-count-primary.csv')\n",
    "links = pd.read_csv('./data/linknode.csv')\n",
    "links = links.set_index('id')\n",
    "res = {}\n",
    "\n",
    "df2 = df[['Link Id','Route_Name','MATSIM volumes']].groupby('Link Id').sum().reset_index()\n",
    "dfm = pd.merge(df[['Link Id','Route_Name']],df2,on=\"Link Id\")\n",
    "dfms = dfm.sort_values(['Route_Name','MATSIM volumes'],ascending =False).reset_index()\n",
    "df2 = df2.set_index('Link Id')\n",
    "validLinkids={\n",
    "    1:29993,\n",
    "    2:22985,\n",
    "    3:41703,\n",
    "    4:50816,\n",
    "    5:36618,\n",
    "    9:40484,\n",
    "    10:20351,\n",
    "    11:53692,\n",
    "    13:11227,\n",
    "    15:32627,\n",
    "    17:60243,\n",
    "    18:35021,\n",
    "    19:6581,\n",
    "    20:44844,\n",
    "    21:11353,\n",
    "    22:15556,\n",
    "    23:54908,\n",
    "    24:12851,\n",
    "    26:39983,\n",
    "    27:1733,\n",
    "}\n",
    "\n",
    "for idx in tqdm_notebook(df.index):\n",
    "    lid = df.at[idx, 'Link Id']\n",
    "    if lid not in validLinkids.values():\n",
    "        continue\n",
    "    key = str(lid)\n",
    "    if key not in res:\n",
    "        desc = ['linkid:' + str(lid), 'mlink:' + str(df.at[idx, 'mlink']),'Route:'+ df.at[idx, 'Route_Name'],'Sum vol:' + str(df2.at[lid,'MATSIM volumes']), str(df.at[idx, 'Hour']) + \":\" +str(df.at[idx, 'MATSIM volumes'])]\n",
    "        desc = '<br/>'.join(desc)\n",
    "        res[key] = {\n",
    "            'desc':desc,\n",
    "            'loc': [links.at[lid, 'y0'],links.at[lid, 'x0']]\n",
    "        }\n",
    "    else:\n",
    "        res[key]['desc'] += \"<br/>\" + str(df.at[idx, 'Hour']) + \":\" +str(df.at[idx, 'MATSIM volumes'])\n",
    "        \n",
    "jsonstr = json.dumps(res)\n",
    "jsonstr = \"var mydata = \" + jsonstr + \";\"\n",
    "with open('./data/data_obs.js','w') as f:\n",
    "    f.write(jsonstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_vol_linkids_foreachroute = []\n",
    "rn = \"\"\n",
    "for idx in dfms.index:\n",
    "    crn = dfms.at[idx,'Route_Name']\n",
    "    if crn != rn:\n",
    "        highest_vol_linkids_foreachroute.append(dfms.at[idx,'Link Id'])\n",
    "    rn = crn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0ec661443540fb9a4bbc09e54e8ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=126576), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/full-link-mlink-count-primary.csv')\n",
    "links = pd.read_csv('./data/linknode.csv')\n",
    "links = links.set_index('id')\n",
    "res = {}\n",
    "\n",
    "for idx in tqdm_notebook(df.index):\n",
    "    lid = df.at[idx, 'Link Id']\n",
    "    if lid not in highest_vol_linkids_foreachroute:\n",
    "        continue\n",
    "    key = str(lid)\n",
    "    if key not in res:\n",
    "        desc = ['linkid:' + str(lid), 'mlink:' + str(df.at[idx, 'mlink']),'Route:'+ df.at[idx, 'Route_Name'],'Sum vol:' + str(df2.at[lid,'MATSIM volumes']), str(df.at[idx, 'Hour']) + \":\" +str(df.at[idx, 'MATSIM volumes'])]\n",
    "        desc = '<br/>'.join(desc)\n",
    "        res[key] = {\n",
    "            'desc':desc,\n",
    "            'loc': [links.at[lid, 'y0'],links.at[lid, 'x0']]\n",
    "        }\n",
    "    else:\n",
    "        res[key]['desc'] += \"<br/>\" + str(df.at[idx, 'Hour']) + \":\" +str(df.at[idx, 'MATSIM volumes'])\n",
    "        \n",
    "jsonstr = json.dumps(res)\n",
    "jsonstr = \"var mydata = \" + jsonstr + \";\"\n",
    "with open('./data/data_maxvol.js','w') as f:\n",
    "    f.write(jsonstr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
